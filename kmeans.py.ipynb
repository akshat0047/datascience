{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K Means Clustering\n",
    "\n",
    "\n",
    "## Our Objective - Perform K-Means Clustering to detect Network Intrusion Attempts (Cybersecurity)\n",
    "\n",
    "![alt text](http://konukoii.com/blog/wp-content/uploads/2017/01/RunyanKmeans.gif \"Logo Title Text 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix math\n",
    "import numpy as np\n",
    "#graphing\n",
    "import matplotlib.pyplot as plt\n",
    "#graphing animation\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load textfile dataset (2D data points)\n",
    "# for each user, how many packets are sent per second and what's the size of a packet\n",
    "#anomalies (DDOS attempts) will have lots of big packets sent in a short amount of time \n",
    "def load_dataset(name):\n",
    "    return np.loadtxt(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#euclidian distance between 2 data points. For as many data points as necessary. \n",
    "def euclidian(a, b):\n",
    "    return np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(k, epsilon=0, distance='euclidian'):\n",
    "    #list to store past centroid\n",
    "    history_centroids = []\n",
    "    #set the distance calculation type \n",
    "    if distance == 'euclidian':\n",
    "        dist_method = euclidian\n",
    "    #set the dataset\n",
    "    dataset = load_dataset('dataset.txt')\n",
    "    # dataset = dataset[:, 0:dataset.shape[1] - 1]\n",
    "    # get the number of rows (instances) and columns (features) from the dataset\n",
    "    num_instances, num_features = dataset.shape\n",
    "    #define k centroids (how many clusters do we want to find?) chosen randomly \n",
    "    prototypes = dataset[np.random.randint(0, num_instances - 1, size=k)]\n",
    "    #set these to our list of past centroid (to show progress over time)\n",
    "    history_centroids.append(prototypes)\n",
    "    #to keep track of centroid at every iteration\n",
    "    prototypes_old = np.zeros(prototypes.shape)\n",
    "    #to store clusters\n",
    "    belongs_to = np.zeros((num_instances, 1))\n",
    "    norm = dist_method(prototypes, prototypes_old)\n",
    "    iteration = 0\n",
    "    while norm > epsilon:\n",
    "        iteration += 1\n",
    "        norm = dist_method(prototypes, prototypes_old)\n",
    "        #for each instance in the dataset\n",
    "        for index_instance, instance in enumerate(dataset):\n",
    "            #define a distance vector of size k\n",
    "            dist_vec = np.zeros((k,1))\n",
    "            #for each centroid\n",
    "            for index_prototype, prototype in enumerate(prototypes):\n",
    "                #compute the distance between x and centroid\n",
    "                dist_vec[index_prototype] = dist_method(prototype, instance)\n",
    "            #find the smallest distance, assign that distance to a cluster\n",
    "            belongs_to[index_instance, 0] = np.argmin(dist_vec)\n",
    "            \n",
    "        tmp_prototypes = np.zeros((k, num_features))\n",
    "        \n",
    "        #for each cluster (k of them)\n",
    "        for index in range(len(prototypes)):\n",
    "            #get all the points assigned to a cluster\n",
    "            instances_close = [i for i in range(len(belongs_to)) if belongs_to[i] == index]\n",
    "            #find the mean of those points, this is our new centroid\n",
    "            prototype = np.mean(dataset[instances_close], axis=0)\n",
    "            #add our new centroid to our new temporary list\n",
    "            tmp_prototypes[index, :] = prototype\n",
    "        \n",
    "        #set the new list to the current list\n",
    "        prototypes = tmp_prototypes\n",
    "        \n",
    "        #add our calculated centroids to our history for plotting\n",
    "        history_centroids.append(tmp_prototypes)\n",
    "\n",
    "    #return calculated centroids, history of them all, and assignments for which cluster each datapoint belongs to\n",
    "    return prototypes, history_centroids, belongs_to\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets define a plotting algorithm for our dataset and our centroids\n",
    "def plot(dataset, history_centroids, belongs_to):\n",
    "    #we'll have 2 colors for each centroid cluster\n",
    "    colors = ['r', 'g']\n",
    "\n",
    "    #split our graph by its axis and actual plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    #for each point in our dataset\n",
    "    for index in range(dataset.shape[0]):\n",
    "        #get all the points assigned to a cluster\n",
    "        instances_close = [i for i in range(len(belongs_to)) if belongs_to[i] == index]\n",
    "        #assign each datapoint in that cluster a color and plot it\n",
    "        for instance_index in instances_close:\n",
    "            ax.plot(dataset[instance_index][0], dataset[instance_index][1], (colors[index] + 'o'))\n",
    "\n",
    "    #lets also log the history of centroids calculated via training\n",
    "    history_points = []\n",
    "    #for each centroid ever calculated\n",
    "    for index, centroids in enumerate(history_centroids):\n",
    "        #print them all out\n",
    "        for inner, item in enumerate(centroids):\n",
    "            if index == 0:\n",
    "                history_points.append(ax.plot(item[0], item[1], 'bo')[0])\n",
    "            else:\n",
    "                history_points[inner].set_data(item[0], item[1])\n",
    "                print(\"centroids {} {}\".format(index, item))\n",
    "\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main file \n",
    "def execute():\n",
    "    #load dataset\n",
    "    dataset = load_dataset('dataset.txt')\n",
    "    #train the model on the data\n",
    "    centroids, history_centroids, belongs_to = kmeans(2)\n",
    "    #plot the results\n",
    "    plot(dataset, history_centroids, belongs_to)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "#do everything\n",
    "execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "def plot_step_by_step(dataset, history_centroids, belongs_to):\n",
    "    colors = ['r', 'g']\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for index in range(dataset.shape[0]):\n",
    "        instances_close = [i for i in range(len(belongs_to)) if belongs_to[i] == index]\n",
    "        for instance_index in instances_close:\n",
    "            ax.plot(dataset[instance_index][0], dataset[instance_index][1], (colors[index] + 'o'))\n",
    "\n",
    "    history_points = []\n",
    "    for index, centroids in enumerate(history_centroids):\n",
    "        for inner, item in enumerate(centroids):\n",
    "            if index == 0:\n",
    "                history_points.append(ax.plot(item[0], item[1], 'bo')[0])\n",
    "            else:\n",
    "                history_points[inner].set_data(item[0], item[1])\n",
    "                print(\"centroids {} {}\".format(index, item))\n",
    "                \n",
    "                plt.pause(0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in history_centroids:\n",
    "    plot_step_by_step(dataset, [item], belongs_to)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
